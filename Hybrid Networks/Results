################################################################################
20 NewsGroups:
KerasBlog_CNN_Classifier
filter_sizes=[5,5,5]
filter_counts=[64,64,64]
learning_rate=0.001
batch_size=64
num_epochs=30

RESULTS:
Total Doc Count :  18846
Label dimention :  (11314, 20)
Starting data Preprocessing
Completed data Preprocessing
Load_Embedings :: GoogleVecs
Num of Docs :  18846
Num of words per Doc :  12044
Number of unique Words :  9994
Words not found in embeddings :  4664
Load_Embedings :: GoogleVecs
Using TensorFlow backend.
Embeddings Shape :  (9994, 300)
Using Nested CNN with parameters : 
Batch-size : 64,  								
Filter-Sizes : [5, 5, 5],  							
Filter-Counts : [64, 64, 64], 							
Pool-Windows : [2, 2, 2]
Nm of classes :  20
Input tensor shape:  (None, 12044)
2018-03-22 18:52:28.534822: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-22 18:52:28.534865: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-22 18:52:28.534885: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Embeddings tensor shape:  (None, 12044, 300)
Convolution shape at loop  0  :  (None, 12040, 64)
Max-Pool shape at loop  0  :  (None, 2408, 64)
Convolution shape at loop  1  :  (None, 2404, 64)
Max-Pool shape at loop  1  :  (None, 480, 64)
Convolution shape at loop  2  :  (None, 476, 64)
Max-Pool shape at loop  2  :  (None, 95, 64)
Train on 9051 samples, validate on 2263 samples
Epoch 1/30
 - 613s - loss: 2.9232 - acc: 0.0765 - val_loss: 2.6480 - val_acc: 0.1246
Epoch 2/30
 - 612s - loss: 2.3528 - acc: 0.1833 - val_loss: 1.9066 - val_acc: 0.2956
Epoch 3/30
 - 470s - loss: 1.6550 - acc: 0.3865 - val_loss: 1.4507 - val_acc: 0.4945
Epoch 4/30
 - 475s - loss: 1.2334 - acc: 0.5420 - val_loss: 1.2777 - val_acc: 0.5700
Epoch 5/30
 - 472s - loss: 0.9829 - acc: 0.6347 - val_loss: 1.1441 - val_acc: 0.6270
Epoch 6/30
 - 557s - loss: 0.8078 - acc: 0.7057 - val_loss: 1.0876 - val_acc: 0.6774
Epoch 7/30
 - 520s - loss: 0.6457 - acc: 0.7662 - val_loss: 1.0878 - val_acc: 0.6889
Epoch 8/30
 - 598s - loss: 0.5230 - acc: 0.8219 - val_loss: 1.0599 - val_acc: 0.7101
Epoch 9/30
 - 537s - loss: 0.4486 - acc: 0.8481 - val_loss: 1.1027 - val_acc: 0.7154
Epoch 10/30
 - 473s - loss: 0.3893 - acc: 0.8697 - val_loss: 1.1446 - val_acc: 0.7397
Epoch 11/30
 - 471s - loss: 0.3389 - acc: 0.8885 - val_loss: 1.2172 - val_acc: 0.7274
Epoch 12/30
 - 471s - loss: 0.2856 - acc: 0.9052 - val_loss: 1.1591 - val_acc: 0.7424
Epoch 13/30
 - 470s - loss: 0.2298 - acc: 0.9245 - val_loss: 1.2346 - val_acc: 0.7512
Epoch 14/30
 - 471s - loss: 0.2246 - acc: 0.9274 - val_loss: 1.3115 - val_acc: 0.7499
Epoch 15/30
 - 473s - loss: 0.1897 - acc: 0.9419 - val_loss: 1.3676 - val_acc: 0.7446
Epoch 16/30
 - 473s - loss: 0.2006 - acc: 0.9365 - val_loss: 1.1950 - val_acc: 0.7627
Epoch 17/30
 - 472s - loss: 0.1623 - acc: 0.9527 - val_loss: 1.2857 - val_acc: 0.7733
Epoch 18/30
 - 471s - loss: 0.1328 - acc: 0.9580 - val_loss: 1.2629 - val_acc: 0.7627
Epoch 19/30
 - 469s - loss: 0.1341 - acc: 0.9572 - val_loss: 1.3572 - val_acc: 0.7764
Epoch 20/30
 - 472s - loss: 0.1266 - acc: 0.9625 - val_loss: 1.2659 - val_acc: 0.7821
Epoch 21/30
 - 472s - loss: 0.1221 - acc: 0.9624 - val_loss: 1.3274 - val_acc: 0.7799
Epoch 22/30
 - 473s - loss: 0.1175 - acc: 0.9657 - val_loss: 1.4264 - val_acc: 0.7782
Epoch 23/30
 - 472s - loss: 0.1187 - acc: 0.9643 - val_loss: 1.3651 - val_acc: 0.7751
Epoch 24/30
 - 472s - loss: 0.1020 - acc: 0.9683 - val_loss: 1.4544 - val_acc: 0.7866
Epoch 25/30
 - 474s - loss: 0.1122 - acc: 0.9681 - val_loss: 1.4879 - val_acc: 0.7777
Epoch 26/30
 - 472s - loss: 0.0870 - acc: 0.9724 - val_loss: 1.5965 - val_acc: 0.7777
Epoch 27/30
 - 470s - loss: 0.1042 - acc: 0.9696 - val_loss: 1.5293 - val_acc: 0.7888
Epoch 28/30
 - 472s - loss: 0.0911 - acc: 0.9720 - val_loss: 1.4583 - val_acc: 0.7791
Epoch 29/30
 - 470s - loss: 0.0772 - acc: 0.9762 - val_loss: 1.3859 - val_acc: 0.7936
Epoch 30/30
 - 471s - loss: 0.0683 - acc: 0.9797 - val_loss: 1.4283 - val_acc: 0.8003
Micro-average quality numbers
Precision: 0.6784, Recall: 0.6784, F1-measure: 0.6784
Macro-average quality numbers
Precision: 0.6781, Recall: 0.6723, F1-measure: 0.6729
All-Class quality numbers
Precision: 
[ 0.71428571  0.53745928  0.646875    0.58838384  0.63930348  0.67317073
  0.58920188  0.53112033  0.76537585  0.81793478  0.92307692  0.87341772
  0.54411765  0.64066194  0.79648241  0.79069767  0.71469741  0.88424437
  0.51274788  0.37942122], 
Recall: 
[ 0.5799373   0.42416452  0.52538071  0.59438776  0.66753247  0.69873418
  0.64358974  0.64646465  0.84422111  0.7581864   0.90225564  0.87121212
  0.5648855   0.68434343  0.80456853  0.76884422  0.68131868  0.73138298
  0.58387097  0.47011952], 
F1-measure: 
[ 0.64013841  0.47413793  0.57983193  0.59137056  0.65311309  0.68571429
  0.61519608  0.58314351  0.80286738  0.7869281   0.91254753  0.87231353
  0.55430712  0.66178266  0.80050505  0.77961783  0.697609    0.80058224
  0.54600302  0.41992883]




#########################################################################################
Reuters 21578
KerasBlog_CNN_Classifier
filter_sizes=[5,5]
filter_counts=[128,128]
learning_rate=0.001
batch_size=64
num_epochs=30

RESULTS:
Label dimention :  (5735, 10)
Starting data Preprocessing
Completed data Preprocessing
Load_Embedings :: GoogleVecs
Num of Docs :  7980
Num of words per Doc :  595
Number of unique Words :  10910
Words not found in embeddings :  3072
Load_Embedings :: GoogleVecs
Using TensorFlow backend.
Embeddings Shape :  (10910, 300)
Using Nested CNN with parameters : 
Batch-size : 64,  								
Filter-Sizes : [5, 5],  							
Filter-Counts : [128, 128], 							
Pool-Windows : [2, 2]
Nm of classes :  10
Input tensor shape:  (None, 595)
2018-03-22 19:54:05.192448: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-22 19:54:05.192508: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-22 19:54:05.192524: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Embeddings tensor shape:  (None, 595, 300)
Convolution shape at loop  0  :  (None, 591, 128)
Max-Pool shape at loop  0  :  (None, 118, 128)
Convolution shape at loop  1  :  (None, 114, 128)
Max-Pool shape at loop  1  :  (None, 22, 128)
Train on 4588 samples, validate on 1147 samples
Epoch 1/30
 - 34s - loss: 0.8400 - acc: 0.6626 - val_loss: 9.8244 - val_acc: 0.1473
Epoch 2/30
 - 31s - loss: 0.3364 - acc: 0.8895 - val_loss: 8.0469 - val_acc: 0.1465
Epoch 3/30
 - 31s - loss: 0.1541 - acc: 0.9486 - val_loss: 10.6487 - val_acc: 0.1482
Epoch 4/30
 - 30s - loss: 0.0744 - acc: 0.9754 - val_loss: 10.3274 - val_acc: 0.1465
Epoch 5/30
 - 31s - loss: 0.0337 - acc: 0.9911 - val_loss: 11.1619 - val_acc: 0.1482
Epoch 6/30
 - 30s - loss: 0.0145 - acc: 0.9972 - val_loss: 11.4847 - val_acc: 0.1465
Epoch 7/30
 - 31s - loss: 0.0085 - acc: 0.9987 - val_loss: 11.8424 - val_acc: 0.1482
Epoch 8/30
 - 30s - loss: 0.0076 - acc: 0.9985 - val_loss: 12.5864 - val_acc: 0.1465
Epoch 9/30
 - 31s - loss: 0.0038 - acc: 0.9993 - val_loss: 13.0881 - val_acc: 0.1465
Epoch 10/30
 - 31s - loss: 0.0050 - acc: 0.9993 - val_loss: 11.8543 - val_acc: 0.1482
Epoch 11/30
 - 31s - loss: 0.0030 - acc: 0.9998 - val_loss: 12.8291 - val_acc: 0.1473
Epoch 12/30
 - 30s - loss: 0.0013 - acc: 0.9998 - val_loss: 12.7947 - val_acc: 0.1482
Epoch 13/30
 - 30s - loss: 8.4326e-04 - acc: 1.0000 - val_loss: 12.5858 - val_acc: 0.1465
Epoch 14/30
 - 31s - loss: 8.0220e-04 - acc: 1.0000 - val_loss: 13.1685 - val_acc: 0.1465
Epoch 15/30
 - 30s - loss: 0.0161 - acc: 0.9950 - val_loss: 11.3591 - val_acc: 0.1473
Epoch 16/30
 - 30s - loss: 0.0048 - acc: 0.9987 - val_loss: 11.8425 - val_acc: 0.1473
Epoch 17/30
 - 30s - loss: 7.9652e-04 - acc: 1.0000 - val_loss: 12.3015 - val_acc: 0.1473
Epoch 18/30
 - 30s - loss: 6.0245e-04 - acc: 0.9998 - val_loss: 12.5215 - val_acc: 0.1473
Epoch 19/30
 - 30s - loss: 3.5156e-04 - acc: 1.0000 - val_loss: 12.6229 - val_acc: 0.1473
Epoch 20/30
 - 35s - loss: 4.8616e-04 - acc: 1.0000 - val_loss: 12.7173 - val_acc: 0.1473
Epoch 21/30
 - 31s - loss: 0.0082 - acc: 0.9976 - val_loss: 11.9034 - val_acc: 0.1465
Epoch 22/30
 - 31s - loss: 0.0018 - acc: 0.9991 - val_loss: 12.1998 - val_acc: 0.1473
Epoch 23/30
 - 30s - loss: 3.6857e-04 - acc: 1.0000 - val_loss: 12.0069 - val_acc: 0.1473
Epoch 24/30
 - 30s - loss: 1.7942e-04 - acc: 1.0000 - val_loss: 12.7313 - val_acc: 0.1473
Epoch 25/30
 - 30s - loss: 2.0002e-04 - acc: 1.0000 - val_loss: 12.6729 - val_acc: 0.1473
Epoch 26/30
 - 30s - loss: 1.6641e-04 - acc: 1.0000 - val_loss: 12.8942 - val_acc: 0.1473
Epoch 27/30
 - 30s - loss: 1.0854e-04 - acc: 1.0000 - val_loss: 12.7713 - val_acc: 0.1473
Epoch 28/30
 - 31s - loss: 0.0186 - acc: 0.9961 - val_loss: 11.4686 - val_acc: 0.1421
Epoch 29/30
 - 30s - loss: 0.0133 - acc: 0.9965 - val_loss: 10.6894 - val_acc: 0.1456
Epoch 30/30
 - 31s - loss: 0.0029 - acc: 0.9991 - val_loss: 11.1964 - val_acc: 0.1456

