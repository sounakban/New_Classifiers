###########################################################################
Twitter


CNN1
filter_sizes=[3,4,5]
filter_counts=[40,40,40]
learning_rate=0.001
batch_size=50
num_epochs=7

RESULTS:
Load_Embedings :: GoogleVecs
Num of Docs :  10000
Number of unique Words :  664
Words not found in embeddings :  105
Load_Embedings :: GoogleVecs
Using TensorFlow backend.
Embeddings Shape :  (664, 300)
Using CNN with parameters : 
Batch-size : 50,  								
Filter-Sizes : [3, 4, 5],  							
Filter-Counts : [40, 40, 40], 							
Pool-Windows : [10, 10, 10]
Num of classes :  2
Input tensor shape:  (None, 15)
2018-05-10 17:44:57.993891: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 17:44:57.993943: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 17:44:57.993963: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Embeddings tensor shape:  (None, 15, 300)
Pre-Pool shape:  (None, 13, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 12, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 11, 40)
Post-Pool shape:  (None, 1, 40)
Train on 6400 samples, validate on 1600 samples
Epoch 1/7
 - 1s - loss: 6.4034 - acc: 0.5827 - val_loss: 2.4250 - val_acc: 0.5869
Epoch 2/7
 - 1s - loss: 1.3576 - acc: 0.6366 - val_loss: 0.8271 - val_acc: 0.6444
Epoch 3/7
 - 1s - loss: 0.7132 - acc: 0.6733 - val_loss: 0.6664 - val_acc: 0.6844
Epoch 4/7
 - 1s - loss: 0.6376 - acc: 0.6966 - val_loss: 0.6149 - val_acc: 0.7088
Epoch 5/7
 - 1s - loss: 0.5946 - acc: 0.7155 - val_loss: 0.5819 - val_acc: 0.7300
Epoch 6/7
 - 1s - loss: 0.5614 - acc: 0.7364 - val_loss: 0.5632 - val_acc: 0.7350
Epoch 7/7
 - 1s - loss: 0.5394 - acc: 0.7427 - val_loss: 0.5483 - val_acc: 0.7488
2000/2000 [==============================] - 0s 41us/step

Test score: 0.575670171529
Test accuracy: 0.704500003159 

Shape of 
1.test_labels :  (2000, 2) 
2.predictions :  (2000, 2)
Micro-average quality numbers
Precision: 0.7045, Recall: 0.7045, F1-measure: 0.7045
Macro-average quality numbers
Precision: 0.7066, Recall: 0.7058, F1-measure: 0.7044
All-Class quality numbers
Precision: 
[ 0.67663551  0.73655914], 
Recall: 
[ 0.74716202  0.66440349], 
F1-measure: 
[ 0.71015204  0.69862315]
Num of train docs per category:
 [4031 3969]
Num of test docs per category:
 [ 969 1031]
Num of classes :  2
Input tensor shape:  (None, 15)
Embeddings tensor shape:  (None, 15, 300)
Pre-Pool shape:  (None, 13, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 12, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 11, 40)
Post-Pool shape:  (None, 1, 40)
Train on 6400 samples, validate on 1600 samples
Epoch 1/7
 - 1s - loss: 5.9472 - acc: 0.5727 - val_loss: 2.2560 - val_acc: 0.5988
Epoch 2/7
 - 1s - loss: 1.2850 - acc: 0.6323 - val_loss: 0.8034 - val_acc: 0.6700
Epoch 3/7
 - 1s - loss: 0.7061 - acc: 0.6633 - val_loss: 0.6666 - val_acc: 0.6794
Epoch 4/7
 - 1s - loss: 0.6361 - acc: 0.6838 - val_loss: 0.6117 - val_acc: 0.7025
Epoch 5/7
 - 1s - loss: 0.5907 - acc: 0.7183 - val_loss: 0.5899 - val_acc: 0.7156
Epoch 6/7
 - 1s - loss: 0.5642 - acc: 0.7358 - val_loss: 0.5603 - val_acc: 0.7313
Epoch 7/7
 - 1s - loss: 0.5422 - acc: 0.7395 - val_loss: 0.5497 - val_acc: 0.7425
2000/2000 [==============================] - 0s 39us/step

Test score: 0.560881948471
Test accuracy: 0.718500003219 

Shape of 
1.test_labels :  (2000, 2) 
2.predictions :  (2000, 2)
Micro-average quality numbers
Precision: 0.7185, Recall: 0.7185, F1-measure: 0.7185
Macro-average quality numbers
Precision: 0.7190, Recall: 0.7179, F1-measure: 0.7179
All-Class quality numbers
Precision: 
[ 0.71202237  0.72599784], 
Recall: 
[ 0.75049116  0.68533605], 
F1-measure: 
[ 0.73075084  0.70508119]
Num of train docs per category:
 [3982 4018]
Num of test docs per category:
 [1018  982]
Num of classes :  2
Input tensor shape:  (None, 15)
Embeddings tensor shape:  (None, 15, 300)
Pre-Pool shape:  (None, 13, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 12, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 11, 40)
Post-Pool shape:  (None, 1, 40)
Train on 6400 samples, validate on 1600 samples
Epoch 1/7
 - 1s - loss: 5.7639 - acc: 0.5667 - val_loss: 2.1970 - val_acc: 0.6056
Epoch 2/7
 - 1s - loss: 1.2741 - acc: 0.6166 - val_loss: 0.8082 - val_acc: 0.6456
Epoch 3/7
 - 1s - loss: 0.7136 - acc: 0.6475 - val_loss: 0.6678 - val_acc: 0.6625
Epoch 4/7
 - 1s - loss: 0.6439 - acc: 0.6755 - val_loss: 0.6206 - val_acc: 0.7006
Epoch 5/7
 - 1s - loss: 0.6016 - acc: 0.7033 - val_loss: 0.5839 - val_acc: 0.7156
Epoch 6/7
 - 1s - loss: 0.5630 - acc: 0.7353 - val_loss: 0.5707 - val_acc: 0.7162
Epoch 7/7
 - 1s - loss: 0.5444 - acc: 0.7362 - val_loss: 0.5549 - val_acc: 0.7244
2000/2000 [==============================] - 0s 40us/step

Test score: 0.535339820385
Test accuracy: 0.745499998331 

Shape of 
1.test_labels :  (2000, 2) 
2.predictions :  (2000, 2)
Micro-average quality numbers
Precision: 0.7455, Recall: 0.7455, F1-measure: 0.7455
Macro-average quality numbers
Precision: 0.7487, Recall: 0.7443, F1-measure: 0.7440
All-Class quality numbers
Precision: 
[ 0.72486772  0.77251732], 
Recall: 
[ 0.80667321  0.68195719], 
F1-measure: 
[ 0.76358569  0.72441798]
Num of train docs per category:
 [3981 4019]
Num of test docs per category:
 [1019  981]
Num of classes :  2
Input tensor shape:  (None, 15)
Embeddings tensor shape:  (None, 15, 300)
Pre-Pool shape:  (None, 13, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 12, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 11, 40)
Post-Pool shape:  (None, 1, 40)
Train on 6400 samples, validate on 1600 samples
Epoch 1/7
 - 1s - loss: 6.4472 - acc: 0.5692 - val_loss: 2.4195 - val_acc: 0.6088
Epoch 2/7
 - 1s - loss: 1.3537 - acc: 0.6439 - val_loss: 0.8231 - val_acc: 0.6688
Epoch 3/7
 - 1s - loss: 0.7125 - acc: 0.6538 - val_loss: 0.6602 - val_acc: 0.6663
Epoch 4/7
 - 1s - loss: 0.6289 - acc: 0.6927 - val_loss: 0.6031 - val_acc: 0.7100
Epoch 5/7
 - 1s - loss: 0.5854 - acc: 0.7141 - val_loss: 0.5708 - val_acc: 0.7337
Epoch 6/7
 - 1s - loss: 0.5531 - acc: 0.7386 - val_loss: 0.5551 - val_acc: 0.7294
Epoch 7/7
 - 1s - loss: 0.5374 - acc: 0.7373 - val_loss: 0.5461 - val_acc: 0.7344
2000/2000 [==============================] - 0s 41us/step

Test score: 0.540654212236
Test accuracy: 0.734999996424 

Shape of 
1.test_labels :  (2000, 2) 
2.predictions :  (2000, 2)
Micro-average quality numbers
Precision: 0.7350, Recall: 0.7350, F1-measure: 0.7350
Macro-average quality numbers
Precision: 0.7400, Recall: 0.7356, F1-measure: 0.7339
All-Class quality numbers
Precision: 
[ 0.70334507  0.77662037], 
Recall: 
[ 0.80544355  0.6656746 ], 
F1-measure: 
[ 0.75093985  0.71688034]
Num of train docs per category:
 [4008 3992]
Num of test docs per category:
 [ 992 1008]
Num of classes :  2
Input tensor shape:  (None, 15)
Embeddings tensor shape:  (None, 15, 300)
Pre-Pool shape:  (None, 13, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 12, 40)
Post-Pool shape:  (None, 1, 40)
Pre-Pool shape:  (None, 11, 40)
Post-Pool shape:  (None, 1, 40)
Train on 6400 samples, validate on 1600 samples
Epoch 1/7
 - 1s - loss: 6.1150 - acc: 0.5794 - val_loss: 2.3142 - val_acc: 0.6575
Epoch 2/7
 - 1s - loss: 1.3049 - acc: 0.6433 - val_loss: 0.8019 - val_acc: 0.6531
Epoch 3/7
 - 1s - loss: 0.7026 - acc: 0.6695 - val_loss: 0.6503 - val_acc: 0.7019
Epoch 4/7
 - 1s - loss: 0.6262 - acc: 0.6988 - val_loss: 0.5993 - val_acc: 0.7144
Epoch 5/7
 - 1s - loss: 0.5845 - acc: 0.7247 - val_loss: 0.5676 - val_acc: 0.7250
Epoch 6/7
 - 1s - loss: 0.5621 - acc: 0.7284 - val_loss: 0.5548 - val_acc: 0.7281
Epoch 7/7
 - 1s - loss: 0.5395 - acc: 0.7394 - val_loss: 0.5476 - val_acc: 0.7275
2000/2000 [==============================] - 0s 40us/step

Test score: 0.548478387296
Test accuracy: 0.736500002444 

Shape of 
1.test_labels :  (2000, 2) 
2.predictions :  (2000, 2)
Micro-average quality numbers
Precision: 0.7365, Recall: 0.7365, F1-measure: 0.7365
Macro-average quality numbers
Precision: 0.7406, Recall: 0.7364, F1-measure: 0.7353
All-Class quality numbers
Precision: 
[ 0.70962048  0.7716263 ], 
Recall: 
[ 0.80239521  0.67034068], 
F1-measure: 
[ 0.75316159  0.71742627]
Num of train docs per category:
 [3998 4002]
Num of test docs per category:
 [1002  998]









###########################################################################
Stack OverFlow


CNN1
filter_sizes=[3,5,7]
filter_counts=[100,100,100]
learning_rate=0.001
batch_size=50
num_epochs=41

RESULTS:
Label dimention :  (20000, 20)
Load_Embedings :: GoogleVecs
Num of Docs :  20000
Number of unique Words :  1113
Words not found in embeddings :  206
Load_Embedings :: GoogleVecs
Using TensorFlow backend.
Embeddings Shape :  (1113, 300)
Using CNN with parameters : 
Batch-size : 50,  								
Filter-Sizes : [3, 5, 7],  							
Filter-Counts : [100, 100, 100], 						
Pool-Windows : [5, 6, 7]
Num of classes :  20
Input tensor shape:  (None, 18)
2018-05-10 23:08:33.775484: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 23:08:33.775544: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 23:08:33.775561: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Embeddings tensor shape:  (None, 18, 300)
Pre-Pool shape:  (None, 16, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 14, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 12, 100)
Post-Pool shape:  (None, 1, 100)
Train on 12800 samples, validate on 3200 samples
Epoch 1/41
 - 4s - loss: 20.2653 - acc: 0.0745 - val_loss: 3.1443 - val_acc: 0.0000e+00
Epoch 2/41
 - 3s - loss: 2.9904 - acc: 0.0609 - val_loss: 3.1624 - val_acc: 0.0309
Epoch 3/41
 - 3s - loss: 2.9885 - acc: 0.0687 - val_loss: 3.1916 - val_acc: 0.0487
Epoch 4/41
 - 3s - loss: 2.9914 - acc: 0.0680 - val_loss: 3.2297 - val_acc: 0.0000e+00
Epoch 5/41
 - 3s - loss: 2.9877 - acc: 0.0795 - val_loss: 3.2493 - val_acc: 0.0219
Epoch 6/41
 - 3s - loss: 2.9537 - acc: 0.0995 - val_loss: 3.1657 - val_acc: 0.0250
Epoch 7/41
 - 3s - loss: 2.8834 - acc: 0.1234 - val_loss: 3.1328 - val_acc: 0.1028
Epoch 8/41
 - 3s - loss: 2.7902 - acc: 0.1523 - val_loss: 2.9672 - val_acc: 0.1078
Epoch 9/41
 - 3s - loss: 2.7209 - acc: 0.1883 - val_loss: 2.8933 - val_acc: 0.1784
Epoch 10/41
 - 3s - loss: 2.6384 - acc: 0.2202 - val_loss: 2.7143 - val_acc: 0.2016
Epoch 11/41
 - 3s - loss: 2.5409 - acc: 0.2597 - val_loss: 2.7541 - val_acc: 0.2413
Epoch 12/41
 - 3s - loss: 2.4638 - acc: 0.2984 - val_loss: 2.6011 - val_acc: 0.2372
Epoch 13/41
 - 3s - loss: 2.4062 - acc: 0.3234 - val_loss: 2.6431 - val_acc: 0.2759
Epoch 14/41
 - 3s - loss: 2.3471 - acc: 0.3497 - val_loss: 2.7043 - val_acc: 0.3031
Epoch 15/41
 - 3s - loss: 2.2955 - acc: 0.3656 - val_loss: 2.4269 - val_acc: 0.2919
Epoch 16/41
 - 3s - loss: 2.2627 - acc: 0.3783 - val_loss: 2.5172 - val_acc: 0.3103
Epoch 17/41
 - 3s - loss: 2.2419 - acc: 0.3921 - val_loss: 2.6762 - val_acc: 0.3291
Epoch 18/41
 - 3s - loss: 2.2147 - acc: 0.4017 - val_loss: 2.5364 - val_acc: 0.3306
Epoch 19/41
 - 3s - loss: 2.1955 - acc: 0.3998 - val_loss: 2.7399 - val_acc: 0.2984
Epoch 20/41
 - 3s - loss: 2.1733 - acc: 0.4116 - val_loss: 2.4367 - val_acc: 0.3106
Epoch 21/41
 - 3s - loss: 2.1588 - acc: 0.4091 - val_loss: 2.3531 - val_acc: 0.3338
Epoch 22/41
 - 3s - loss: 2.1412 - acc: 0.4212 - val_loss: 2.5612 - val_acc: 0.3122
Epoch 23/41
 - 3s - loss: 2.1272 - acc: 0.4256 - val_loss: 2.4615 - val_acc: 0.3256
Epoch 24/41
 - 3s - loss: 2.1145 - acc: 0.4276 - val_loss: 2.4923 - val_acc: 0.3397
Epoch 25/41
 - 3s - loss: 2.1048 - acc: 0.4314 - val_loss: 2.3880 - val_acc: 0.3338
Epoch 26/41
 - 3s - loss: 2.0883 - acc: 0.4408 - val_loss: 2.4382 - val_acc: 0.3394
Epoch 27/41
 - 3s - loss: 2.0840 - acc: 0.4405 - val_loss: 2.3441 - val_acc: 0.3831
Epoch 28/41
 - 3s - loss: 2.0718 - acc: 0.4380 - val_loss: 2.4228 - val_acc: 0.3422
Epoch 29/41
 - 3s - loss: 2.0676 - acc: 0.4423 - val_loss: 2.1919 - val_acc: 0.4088
Epoch 30/41
 - 3s - loss: 2.0473 - acc: 0.4533 - val_loss: 2.1623 - val_acc: 0.4244
Epoch 31/41
 - 3s - loss: 2.0582 - acc: 0.4487 - val_loss: 2.2742 - val_acc: 0.3953
Epoch 32/41
 - 3s - loss: 2.0361 - acc: 0.4563 - val_loss: 2.1854 - val_acc: 0.4263
Epoch 33/41
 - 3s - loss: 2.0178 - acc: 0.4603 - val_loss: 2.2163 - val_acc: 0.4094
Epoch 34/41
 - 3s - loss: 2.0296 - acc: 0.4602 - val_loss: 2.2078 - val_acc: 0.4309
Epoch 35/41
 - 3s - loss: 2.0221 - acc: 0.4570 - val_loss: 2.2832 - val_acc: 0.3772
Epoch 36/41
 - 3s - loss: 2.0026 - acc: 0.4627 - val_loss: 2.2626 - val_acc: 0.4069
Epoch 37/41
 - 3s - loss: 2.0146 - acc: 0.4631 - val_loss: 2.3402 - val_acc: 0.3863
Epoch 38/41
 - 3s - loss: 2.0026 - acc: 0.4636 - val_loss: 2.2848 - val_acc: 0.3925
Epoch 39/41
 - 3s - loss: 1.9969 - acc: 0.4660 - val_loss: 2.1532 - val_acc: 0.4381
Epoch 40/41
 - 3s - loss: 1.9830 - acc: 0.4716 - val_loss: 2.3321 - val_acc: 0.4169
Epoch 41/41
 - 3s - loss: 1.9717 - acc: 0.4730 - val_loss: 2.2045 - val_acc: 0.4306
4000/4000 [==============================] - 0s 62us/step

Test score: 2.44546747655
Test accuracy: 0.362250001729 

Shape of 
1.test_labels :  (4000, 20) 
2.predictions :  (4000, 20)
Micro-average quality numbers
Precision: 0.3623, Recall: 0.3623, F1-measure: 0.3623
Macro-average quality numbers
Precision: 0.4122, Recall: 0.3613, F1-measure: 0.3434
All-Class quality numbers
Precision: 
[ 0.28571429  0.57768924  0.82330827  0.42009132  0.71428571  0.15508021
  0.75        0.10589651  0.33540373  0.52132701  0.625       0.2195122
  0.14        0.8015873   0.30522088  0.06091371  0.13636364  0.42162162
  0.44444444  0.4       ], 
Recall: 
[ 0.28571429  0.35194175  0.48026316  0.50828729  0.34632035  0.46774194
  0.34194529  0.38938053  0.26470588  0.6547619   0.34090909  0.38709677
  0.21875     0.22295806  0.41304348  0.3         0.47727273  0.25742574
  0.26666667  0.25      ], 
F1-measure: 
[ 0.28571429  0.43740573  0.6066482   0.46        0.4664723   0.23293173
  0.4697286   0.16650899  0.29589041  0.58047493  0.44117647  0.28015564
  0.17073171  0.34887737  0.35103926  0.10126582  0.21212121  0.31967213
  0.33333333  0.30769231]
Num of train docs per category:
 [958 588 544 819 769 938 342 774 796 832 912 907 968 547 816 920 956 697
 925 992]
Num of test docs per category:
 [ 42 412 456 181 231  62 658 226 204 168  88  93  32 453 184  80  44 303
  75   8]
Num of classes :  20
Input tensor shape:  (None, 18)
Embeddings tensor shape:  (None, 18, 300)
Pre-Pool shape:  (None, 16, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 14, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 12, 100)
Post-Pool shape:  (None, 1, 100)
Train on 12800 samples, validate on 3200 samples
Epoch 1/41
 - 3s - loss: 20.2743 - acc: 0.0769 - val_loss: 3.1908 - val_acc: 0.0306
Epoch 2/41
 - 3s - loss: 2.9925 - acc: 0.0657 - val_loss: 3.2085 - val_acc: 0.0372
Epoch 3/41
 - 3s - loss: 2.9925 - acc: 0.0670 - val_loss: 3.2008 - val_acc: 0.0244
Epoch 4/41
 - 3s - loss: 2.9935 - acc: 0.0716 - val_loss: 3.1991 - val_acc: 0.0372
Epoch 5/41
 - 3s - loss: 2.9872 - acc: 0.0803 - val_loss: 3.1934 - val_acc: 0.0381
Epoch 6/41
 - 4s - loss: 2.9272 - acc: 0.1116 - val_loss: 3.2099 - val_acc: 0.0381
Epoch 7/41
 - 5s - loss: 2.8467 - acc: 0.1334 - val_loss: 3.1423 - val_acc: 0.0738
Epoch 8/41
 - 4s - loss: 2.7935 - acc: 0.1458 - val_loss: 2.9895 - val_acc: 0.0962
Epoch 9/41
 - 5s - loss: 2.7472 - acc: 0.1714 - val_loss: 2.9716 - val_acc: 0.1444
Epoch 10/41
 - 5s - loss: 2.6725 - acc: 0.2098 - val_loss: 2.9052 - val_acc: 0.1647
Epoch 11/41
 - 5s - loss: 2.5871 - acc: 0.2559 - val_loss: 2.8574 - val_acc: 0.1788
Epoch 12/41
 - 5s - loss: 2.5031 - acc: 0.2917 - val_loss: 2.6865 - val_acc: 0.2628
Epoch 13/41
 - 5s - loss: 2.4256 - acc: 0.3274 - val_loss: 2.7707 - val_acc: 0.2659
Epoch 14/41
 - 5s - loss: 2.3863 - acc: 0.3407 - val_loss: 2.5153 - val_acc: 0.2931
Epoch 15/41
 - 5s - loss: 2.3465 - acc: 0.3496 - val_loss: 2.5809 - val_acc: 0.2800
Epoch 16/41
 - 5s - loss: 2.3032 - acc: 0.3655 - val_loss: 2.5317 - val_acc: 0.2856
Epoch 17/41
 - 5s - loss: 2.2823 - acc: 0.3723 - val_loss: 2.5042 - val_acc: 0.2987
Epoch 18/41
 - 5s - loss: 2.2695 - acc: 0.3782 - val_loss: 2.5624 - val_acc: 0.3238
Epoch 19/41
 - 5s - loss: 2.2350 - acc: 0.3868 - val_loss: 2.4205 - val_acc: 0.3166
Epoch 20/41
 - 5s - loss: 2.2227 - acc: 0.3912 - val_loss: 2.6052 - val_acc: 0.3353
Epoch 21/41
 - 5s - loss: 2.2169 - acc: 0.3944 - val_loss: 2.4276 - val_acc: 0.3350
Epoch 22/41
 - 5s - loss: 2.1909 - acc: 0.4038 - val_loss: 2.6362 - val_acc: 0.3175
Epoch 23/41
 - 5s - loss: 2.1762 - acc: 0.4051 - val_loss: 2.4770 - val_acc: 0.3356
Epoch 24/41
 - 5s - loss: 2.1571 - acc: 0.4143 - val_loss: 2.4986 - val_acc: 0.3309
Epoch 25/41
 - 5s - loss: 2.1521 - acc: 0.4199 - val_loss: 2.4700 - val_acc: 0.3231
Epoch 26/41
 - 5s - loss: 2.1299 - acc: 0.4264 - val_loss: 2.3068 - val_acc: 0.3359
Epoch 27/41
 - 5s - loss: 2.1294 - acc: 0.4277 - val_loss: 2.4768 - val_acc: 0.3072
Epoch 28/41
 - 5s - loss: 2.1225 - acc: 0.4318 - val_loss: 2.4076 - val_acc: 0.3297
Epoch 29/41
 - 5s - loss: 2.1082 - acc: 0.4336 - val_loss: 2.5554 - val_acc: 0.3188
Epoch 30/41
 - 5s - loss: 2.1032 - acc: 0.4383 - val_loss: 2.4054 - val_acc: 0.3294
Epoch 31/41
 - 5s - loss: 2.0978 - acc: 0.4393 - val_loss: 2.4057 - val_acc: 0.3397
Epoch 32/41
 - 5s - loss: 2.0773 - acc: 0.4410 - val_loss: 2.4297 - val_acc: 0.3625
Epoch 33/41
 - 5s - loss: 2.0775 - acc: 0.4461 - val_loss: 2.4380 - val_acc: 0.3159
Epoch 34/41
 - 5s - loss: 2.0805 - acc: 0.4447 - val_loss: 2.4875 - val_acc: 0.3356
Epoch 35/41
 - 5s - loss: 2.0540 - acc: 0.4508 - val_loss: 2.3682 - val_acc: 0.3300
Epoch 36/41
 - 5s - loss: 2.0553 - acc: 0.4528 - val_loss: 2.3480 - val_acc: 0.3563
Epoch 37/41
 - 5s - loss: 2.0469 - acc: 0.4543 - val_loss: 2.2955 - val_acc: 0.3866
Epoch 38/41
 - 5s - loss: 2.0398 - acc: 0.4580 - val_loss: 2.2609 - val_acc: 0.3891
Epoch 39/41
 - 5s - loss: 2.0364 - acc: 0.4575 - val_loss: 2.2588 - val_acc: 0.4138
Epoch 40/41
 - 5s - loss: 2.0321 - acc: 0.4567 - val_loss: 2.5127 - val_acc: 0.3369
Epoch 41/41
 - 5s - loss: 2.0154 - acc: 0.4675 - val_loss: 2.2270 - val_acc: 0.4191
4000/4000 [==============================] - 0s 110us/step

Test score: 2.16331342459
Test accuracy: 0.41525000073 

Shape of 
1.test_labels :  (4000, 20) 
2.predictions :  (4000, 20)
Micro-average quality numbers
Precision: 0.4153, Recall: 0.4153, F1-measure: 0.4153
Macro-average quality numbers
Precision: 0.4287, Recall: 0.4015, F1-measure: 0.4029
All-Class quality numbers
Precision: 
[ 0.49122807  0.54077253  0.8045977   0.67164179  0.53424658  0.45454545
  0.6194332   0.21799308  0.10703364  0.52488688  0.25688073  0.41004184
  0.21590909  0.52173913  0.45049505  0.21794872  0.32        0.51428571
  0.25581395  0.44444444], 
Recall: 
[ 0.46666667  0.3423913   0.58823529  0.49180328  0.43093923  0.4375
  0.44736842  0.18529412  0.4375      0.68639053  0.25688073  0.56321839
  0.26027397  0.47599165  0.42924528  0.28571429  0.36363636  0.33566434
  0.25882353  0.28571429], 
F1-measure: 
[ 0.47863248  0.41930116  0.67961165  0.56782334  0.47706422  0.44585987
  0.51952462  0.20031797  0.17199017  0.59487179  0.25688073  0.47457627
  0.23602484  0.49781659  0.43961353  0.24727273  0.34042553  0.40620592
  0.25730994  0.34782609]
Num of train docs per category:
 [940 632 643 817 819 920 658 660 840 831 891 826 927 521 788 881 934 571
 915 986]
Num of test docs per category:
 [ 60 368 357 183 181  80 342 340 160 169 109 174  73 479 212 119  66 429
  85  14]
Num of classes :  20
Input tensor shape:  (None, 18)
Embeddings tensor shape:  (None, 18, 300)
Pre-Pool shape:  (None, 16, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 14, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 12, 100)
Post-Pool shape:  (None, 1, 100)
Train on 12800 samples, validate on 3200 samples
Epoch 1/41
 - 5s - loss: 20.8704 - acc: 0.0758 - val_loss: 3.3777 - val_acc: 0.0000e+00
Epoch 2/41
 - 5s - loss: 2.9824 - acc: 0.0691 - val_loss: 3.3440 - val_acc: 0.0000e+00
Epoch 3/41
 - 5s - loss: 2.9828 - acc: 0.0737 - val_loss: 3.3706 - val_acc: 0.0000e+00
Epoch 4/41
 - 5s - loss: 2.9824 - acc: 0.0718 - val_loss: 3.2740 - val_acc: 0.0000e+00
Epoch 5/41
 - 5s - loss: 2.9747 - acc: 0.0790 - val_loss: 3.2536 - val_acc: 0.0053
Epoch 6/41
 - 5s - loss: 2.9289 - acc: 0.0935 - val_loss: 3.2367 - val_acc: 0.0212
Epoch 7/41
 - 5s - loss: 2.8749 - acc: 0.1127 - val_loss: 3.2944 - val_acc: 0.0234
Epoch 8/41
 - 5s - loss: 2.8289 - acc: 0.1373 - val_loss: 3.2215 - val_acc: 0.0266
Epoch 9/41
 - 5s - loss: 2.7438 - acc: 0.1904 - val_loss: 3.2624 - val_acc: 0.0391
Epoch 10/41
 - 5s - loss: 2.6382 - acc: 0.2311 - val_loss: 3.0623 - val_acc: 0.0941
Epoch 11/41
 - 5s - loss: 2.5444 - acc: 0.2673 - val_loss: 3.0238 - val_acc: 0.1291
Epoch 12/41
 - 5s - loss: 2.4686 - acc: 0.3002 - val_loss: 2.9118 - val_acc: 0.1891
Epoch 13/41
 - 5s - loss: 2.4083 - acc: 0.3170 - val_loss: 2.7879 - val_acc: 0.2184
Epoch 14/41
 - 5s - loss: 2.3759 - acc: 0.3330 - val_loss: 2.7509 - val_acc: 0.2094
Epoch 15/41
 - 5s - loss: 2.3338 - acc: 0.3493 - val_loss: 2.7787 - val_acc: 0.2503
Epoch 16/41
 - 5s - loss: 2.3077 - acc: 0.3607 - val_loss: 2.6709 - val_acc: 0.2363
Epoch 17/41
 - 5s - loss: 2.2779 - acc: 0.3730 - val_loss: 2.7245 - val_acc: 0.2822
Epoch 18/41
 - 5s - loss: 2.2558 - acc: 0.3829 - val_loss: 2.7148 - val_acc: 0.2853
Epoch 19/41
 - 5s - loss: 2.2321 - acc: 0.3881 - val_loss: 2.8075 - val_acc: 0.2875
Epoch 20/41
 - 5s - loss: 2.2124 - acc: 0.3971 - val_loss: 2.7318 - val_acc: 0.2619
Epoch 21/41
 - 5s - loss: 2.2013 - acc: 0.4004 - val_loss: 2.6421 - val_acc: 0.2647
Epoch 22/41
 - 5s - loss: 2.1823 - acc: 0.4080 - val_loss: 2.4793 - val_acc: 0.2941
Epoch 23/41
 - 5s - loss: 2.1783 - acc: 0.4137 - val_loss: 2.5632 - val_acc: 0.3078
Epoch 24/41
 - 5s - loss: 2.1634 - acc: 0.4147 - val_loss: 2.5949 - val_acc: 0.2641
Epoch 25/41
 - 5s - loss: 2.1518 - acc: 0.4190 - val_loss: 2.6521 - val_acc: 0.2944
Epoch 26/41
 - 5s - loss: 2.1356 - acc: 0.4286 - val_loss: 2.7141 - val_acc: 0.2913
Epoch 27/41
 - 5s - loss: 2.1265 - acc: 0.4265 - val_loss: 2.6552 - val_acc: 0.3172
Epoch 28/41
 - 5s - loss: 2.1188 - acc: 0.4314 - val_loss: 2.4979 - val_acc: 0.3078
Epoch 29/41
 - 4s - loss: 2.1037 - acc: 0.4399 - val_loss: 2.5501 - val_acc: 0.3112
Epoch 30/41
 - 5s - loss: 2.1026 - acc: 0.4412 - val_loss: 2.6458 - val_acc: 0.3087
Epoch 31/41
 - 5s - loss: 2.0813 - acc: 0.4453 - val_loss: 2.4257 - val_acc: 0.3194
Epoch 32/41
 - 5s - loss: 2.0838 - acc: 0.4480 - val_loss: 2.5640 - val_acc: 0.3138
Epoch 33/41
 - 5s - loss: 2.0695 - acc: 0.4544 - val_loss: 2.4931 - val_acc: 0.3200
Epoch 34/41
 - 5s - loss: 2.0644 - acc: 0.4526 - val_loss: 2.4446 - val_acc: 0.3269
Epoch 35/41
 - 5s - loss: 2.0620 - acc: 0.4545 - val_loss: 2.5348 - val_acc: 0.2941
Epoch 36/41
 - 5s - loss: 2.0386 - acc: 0.4603 - val_loss: 2.4790 - val_acc: 0.3197
Epoch 37/41
 - 5s - loss: 2.0445 - acc: 0.4632 - val_loss: 2.3959 - val_acc: 0.3428
Epoch 38/41
 - 5s - loss: 2.0286 - acc: 0.4666 - val_loss: 2.4839 - val_acc: 0.3525
Epoch 39/41
 - 5s - loss: 2.0268 - acc: 0.4654 - val_loss: 2.5735 - val_acc: 0.3359
Epoch 40/41
 - 5s - loss: 2.0162 - acc: 0.4674 - val_loss: 2.4453 - val_acc: 0.3503
Epoch 41/41
 - 5s - loss: 2.0118 - acc: 0.4678 - val_loss: 2.4317 - val_acc: 0.3538
4000/4000 [==============================] - 0s 99us/step

Test score: 2.29403980821
Test accuracy: 0.379000001773 

Shape of 
1.test_labels :  (4000, 20) 
2.predictions :  (4000, 20)
Micro-average quality numbers
Precision: 0.3790, Recall: 0.3790, F1-measure: 0.3790
/home/sounak/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
/home/sounak/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Macro-average quality numbers
Precision: 0.5063, Recall: 0.3681, F1-measure: 0.3975
All-Class quality numbers
Precision: 
[ 0.69172932  0.35272727  0.62686567  0.72857143  0.5617284   0.52542373
  0.          0.52        0.36163522  0.73933649  0.52941176  0.62937063
  0.859375    0.20481928  0.48134328  0.44871795  0.58823529  0.31024096
  0.25125628  0.71428571], 
Recall: 
[ 0.49462366  0.44090909  0.67379679  0.5         0.40088106  0.28181818
  0.          0.14976959  0.45634921  0.66382979  0.24456522  0.38297872
  0.25581395  0.5         0.49615385  0.12635379  0.37037037  0.38432836
  0.35460993  0.18518519], 
F1-measure: 
[ 0.57680251  0.39191919  0.64948454  0.59302326  0.46786632  0.36686391
  0.          0.23255814  0.40350877  0.69955157  0.33457249  0.47619048
  0.39426523  0.29059829  0.48863636  0.1971831   0.45454545  0.34333333
  0.29411765  0.29411765]
Num of train docs per category:
 [ 814  780  813  796  773  890 1000  566  748  765  816  765  785  932  740
  723  757  732  859  946]
Num of test docs per category:
 [186 220 187 204 227 110   0 434 252 235 184 235 215  68 260 277 243 268
 141  54]
Num of classes :  20
Input tensor shape:  (None, 18)
Embeddings tensor shape:  (None, 18, 300)
Pre-Pool shape:  (None, 16, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 14, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 12, 100)
Post-Pool shape:  (None, 1, 100)
Train on 12800 samples, validate on 3200 samples
Epoch 1/41
 - 5s - loss: 20.4075 - acc: 0.0845 - val_loss: 3.4951 - val_acc: 0.0000e+00
Epoch 2/41
 - 5s - loss: 2.9491 - acc: 0.0802 - val_loss: 3.6472 - val_acc: 0.0000e+00
Epoch 3/41
 - 5s - loss: 2.9445 - acc: 0.0825 - val_loss: 3.5851 - val_acc: 0.0000e+00
Epoch 4/41
 - 5s - loss: 2.9427 - acc: 0.0893 - val_loss: 3.5797 - val_acc: 0.0000e+00
Epoch 5/41
 - 5s - loss: 2.9071 - acc: 0.1076 - val_loss: 3.6540 - val_acc: 0.0000e+00
Epoch 6/41
 - 5s - loss: 2.8334 - acc: 0.1323 - val_loss: 3.5701 - val_acc: 0.0000e+00
Epoch 7/41
 - 5s - loss: 2.7809 - acc: 0.1579 - val_loss: 3.5051 - val_acc: 0.0225
Epoch 8/41
 - 5s - loss: 2.7310 - acc: 0.1866 - val_loss: 3.4178 - val_acc: 0.0191
Epoch 9/41
 - 5s - loss: 2.6507 - acc: 0.2262 - val_loss: 3.4900 - val_acc: 0.0369
Epoch 10/41
 - 5s - loss: 2.5642 - acc: 0.2583 - val_loss: 3.4253 - val_acc: 0.0441
Epoch 11/41
 - 5s - loss: 2.4965 - acc: 0.2805 - val_loss: 3.3969 - val_acc: 0.0619
Epoch 12/41
 - 5s - loss: 2.4482 - acc: 0.3058 - val_loss: 3.2113 - val_acc: 0.0925
Epoch 13/41
 - 5s - loss: 2.4108 - acc: 0.3201 - val_loss: 3.3819 - val_acc: 0.1044
Epoch 14/41
 - 5s - loss: 2.3684 - acc: 0.3404 - val_loss: 3.1453 - val_acc: 0.1422
Epoch 15/41
 - 5s - loss: 2.3342 - acc: 0.3552 - val_loss: 3.1018 - val_acc: 0.1481
Epoch 16/41
 - 5s - loss: 2.3238 - acc: 0.3619 - val_loss: 3.2458 - val_acc: 0.1625
Epoch 17/41
 - 5s - loss: 2.2890 - acc: 0.3696 - val_loss: 3.1120 - val_acc: 0.1619
Epoch 18/41
 - 5s - loss: 2.2669 - acc: 0.3807 - val_loss: 2.9425 - val_acc: 0.1953
Epoch 19/41
 - 5s - loss: 2.2411 - acc: 0.3867 - val_loss: 3.0349 - val_acc: 0.2072
Epoch 20/41
 - 5s - loss: 2.2308 - acc: 0.3914 - val_loss: 2.9754 - val_acc: 0.2063
Epoch 21/41
 - 5s - loss: 2.2051 - acc: 0.4006 - val_loss: 3.0160 - val_acc: 0.2200
Epoch 22/41
 - 5s - loss: 2.1780 - acc: 0.4098 - val_loss: 2.9561 - val_acc: 0.2197
Epoch 23/41
 - 5s - loss: 2.1702 - acc: 0.4132 - val_loss: 2.8475 - val_acc: 0.2400
Epoch 24/41
 - 5s - loss: 2.1609 - acc: 0.4178 - val_loss: 2.8161 - val_acc: 0.2456
Epoch 25/41
 - 5s - loss: 2.1372 - acc: 0.4289 - val_loss: 2.5920 - val_acc: 0.2469
Epoch 26/41
 - 5s - loss: 2.1322 - acc: 0.4311 - val_loss: 2.9654 - val_acc: 0.2478
Epoch 27/41
 - 5s - loss: 2.1140 - acc: 0.4349 - val_loss: 3.0393 - val_acc: 0.2384
Epoch 28/41
 - 5s - loss: 2.1155 - acc: 0.4346 - val_loss: 2.8627 - val_acc: 0.2406
Epoch 29/41
 - 5s - loss: 2.0872 - acc: 0.4412 - val_loss: 3.0195 - val_acc: 0.2225
Epoch 30/41
 - 5s - loss: 2.0852 - acc: 0.4420 - val_loss: 2.8050 - val_acc: 0.2544
Epoch 31/41
 - 5s - loss: 2.0979 - acc: 0.4377 - val_loss: 2.8435 - val_acc: 0.2791
Epoch 32/41
 - 5s - loss: 2.0644 - acc: 0.4508 - val_loss: 2.8558 - val_acc: 0.2419
Epoch 33/41
 - 5s - loss: 2.0645 - acc: 0.4524 - val_loss: 2.6040 - val_acc: 0.2762
Epoch 34/41
 - 5s - loss: 2.0458 - acc: 0.4531 - val_loss: 2.9766 - val_acc: 0.2547
Epoch 35/41
 - 5s - loss: 2.0544 - acc: 0.4512 - val_loss: 2.9914 - val_acc: 0.2812
Epoch 36/41
 - 5s - loss: 2.0527 - acc: 0.4536 - val_loss: 2.7980 - val_acc: 0.2491
Epoch 37/41
 - 5s - loss: 2.0223 - acc: 0.4672 - val_loss: 2.7520 - val_acc: 0.2441
Epoch 38/41
 - 5s - loss: 2.0322 - acc: 0.4609 - val_loss: 2.7941 - val_acc: 0.2541
Epoch 39/41
 - 5s - loss: 2.0313 - acc: 0.4619 - val_loss: 2.7212 - val_acc: 0.2834
Epoch 40/41
 - 5s - loss: 2.0152 - acc: 0.4702 - val_loss: 2.6763 - val_acc: 0.2822
Epoch 41/41
 - 5s - loss: 2.0140 - acc: 0.4690 - val_loss: 2.9449 - val_acc: 0.2422
4000/4000 [==============================] - 0s 101us/step

Test score: 2.42285983413
Test accuracy: 0.354249999858 

Shape of 
1.test_labels :  (4000, 20) 
2.predictions :  (4000, 20)
Micro-average quality numbers
Precision: 0.3543, Recall: 0.3543, F1-measure: 0.3543
/home/sounak/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/sounak/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Macro-average quality numbers
Precision: 0.4688, Recall: 0.2350, F1-measure: 0.2933
All-Class quality numbers
Precision: 
[ 0.86896552  0.          0.          0.67597765  0.85        0.65363128
  0.          0.          0.5620915   0.82142857  0.98039216  0.60627178
  0.58685446  0.          0.70833333  0.75        0.56133829  0.          0.75
  0.        ], 
Recall: 
[ 0.41176471  0.          0.          0.47081712  0.49097473  0.42545455
  0.          0.          0.26625387  0.53281853  0.17361111  0.51632047
  0.41390728  0.          0.39534884  0.13670886  0.45074627  0.
  0.01522843  0.        ], 
F1-measure: 
[ 0.55875831  0.          0.          0.55504587  0.62242563  0.5154185   0.
  0.          0.36134454  0.64637002  0.29498525  0.55769231  0.48543689
  0.          0.50746269  0.23126338  0.5         0.          0.02985075
  0.        ]
Num of train docs per category:
 [ 694 1000 1000  743  723  725 1000 1000  677  741  712  663  698 1000  656
  605  665 1000  803  895]
Num of test docs per category:
 [306   0   0 257 277 275   0   0 323 259 288 337 302   0 344 395 335   0
 197 105]
Num of classes :  20
Input tensor shape:  (None, 18)
Embeddings tensor shape:  (None, 18, 300)
Pre-Pool shape:  (None, 16, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 14, 100)
Post-Pool shape:  (None, 1, 100)
Pre-Pool shape:  (None, 12, 100)
Post-Pool shape:  (None, 1, 100)
Train on 12800 samples, validate on 3200 samples
Epoch 1/41
 - 5s - loss: 20.3871 - acc: 0.0877 - val_loss: 3.1993 - val_acc: 0.0000e+00
Epoch 2/41
 - 5s - loss: 2.9418 - acc: 0.0869 - val_loss: 3.1841 - val_acc: 0.0000e+00
Epoch 3/41
 - 5s - loss: 2.9413 - acc: 0.0818 - val_loss: 3.2226 - val_acc: 0.0000e+00
Epoch 4/41
 - 5s - loss: 2.9373 - acc: 0.0851 - val_loss: 3.1748 - val_acc: 0.0000e+00
Epoch 5/41
 - 5s - loss: 2.9162 - acc: 0.1040 - val_loss: 3.3008 - val_acc: 0.0000e+00
Epoch 6/41
 - 5s - loss: 2.8369 - acc: 0.1316 - val_loss: 3.1611 - val_acc: 0.0353
Epoch 7/41
 - 5s - loss: 2.7902 - acc: 0.1453 - val_loss: 3.2032 - val_acc: 0.0328
Epoch 8/41
 - 5s - loss: 2.7208 - acc: 0.1917 - val_loss: 3.0970 - val_acc: 0.0791
Epoch 9/41
 - 5s - loss: 2.6185 - acc: 0.2341 - val_loss: 3.0406 - val_acc: 0.0912
Epoch 10/41
 - 5s - loss: 2.5342 - acc: 0.2761 - val_loss: 2.8695 - val_acc: 0.1334
Epoch 11/41
 - 5s - loss: 2.4791 - acc: 0.2904 - val_loss: 2.9240 - val_acc: 0.1159
Epoch 12/41
 - 5s - loss: 2.4369 - acc: 0.3104 - val_loss: 2.7293 - val_acc: 0.1659
Epoch 13/41
 - 5s - loss: 2.3837 - acc: 0.3276 - val_loss: 2.6821 - val_acc: 0.2384
Epoch 14/41
 - 5s - loss: 2.3535 - acc: 0.3444 - val_loss: 2.7471 - val_acc: 0.2144
Epoch 15/41
 - 5s - loss: 2.3155 - acc: 0.3611 - val_loss: 2.6843 - val_acc: 0.2297
Epoch 16/41
 - 5s - loss: 2.2995 - acc: 0.3688 - val_loss: 2.5311 - val_acc: 0.2828
Epoch 17/41
 - 5s - loss: 2.2600 - acc: 0.3794 - val_loss: 2.5419 - val_acc: 0.2759
Epoch 18/41
 - 5s - loss: 2.2467 - acc: 0.3920 - val_loss: 2.4813 - val_acc: 0.3228
Epoch 19/41
 - 5s - loss: 2.2242 - acc: 0.3957 - val_loss: 2.5799 - val_acc: 0.2819
Epoch 20/41
 - 5s - loss: 2.2106 - acc: 0.4027 - val_loss: 2.5163 - val_acc: 0.2791
Epoch 21/41
 - 5s - loss: 2.2002 - acc: 0.4092 - val_loss: 2.4832 - val_acc: 0.3291
Epoch 22/41
 - 5s - loss: 2.1851 - acc: 0.4104 - val_loss: 2.3785 - val_acc: 0.3575
Epoch 23/41
 - 5s - loss: 2.1721 - acc: 0.4188 - val_loss: 2.4900 - val_acc: 0.3003
Epoch 24/41
 - 5s - loss: 2.1589 - acc: 0.4231 - val_loss: 2.4312 - val_acc: 0.3456
Epoch 25/41
 - 5s - loss: 2.1443 - acc: 0.4261 - val_loss: 2.3920 - val_acc: 0.3584
Epoch 26/41
 - 5s - loss: 2.1366 - acc: 0.4250 - val_loss: 2.4022 - val_acc: 0.3672
Epoch 27/41
 - 5s - loss: 2.1183 - acc: 0.4316 - val_loss: 2.3828 - val_acc: 0.3653
Epoch 28/41
 - 5s - loss: 2.1088 - acc: 0.4393 - val_loss: 2.5579 - val_acc: 0.3212
Epoch 29/41
 - 5s - loss: 2.1082 - acc: 0.4395 - val_loss: 2.3970 - val_acc: 0.3481
Epoch 30/41
 - 5s - loss: 2.0794 - acc: 0.4485 - val_loss: 2.4190 - val_acc: 0.3644
Epoch 31/41
 - 5s - loss: 2.0754 - acc: 0.4476 - val_loss: 2.4408 - val_acc: 0.3616
Epoch 32/41
 - 5s - loss: 2.0750 - acc: 0.4474 - val_loss: 2.3714 - val_acc: 0.3681
Epoch 33/41
 - 5s - loss: 2.0714 - acc: 0.4483 - val_loss: 2.3784 - val_acc: 0.3844
Epoch 34/41
 - 5s - loss: 2.0661 - acc: 0.4504 - val_loss: 2.3864 - val_acc: 0.3597
Epoch 35/41
 - 5s - loss: 2.0495 - acc: 0.4566 - val_loss: 2.4271 - val_acc: 0.3647
Epoch 36/41
 - 5s - loss: 2.0520 - acc: 0.4560 - val_loss: 2.3103 - val_acc: 0.3881
Epoch 37/41
 - 5s - loss: 2.0403 - acc: 0.4591 - val_loss: 2.4597 - val_acc: 0.3450
Epoch 38/41
 - 5s - loss: 2.0381 - acc: 0.4617 - val_loss: 2.3629 - val_acc: 0.3641
Epoch 39/41
 - 5s - loss: 2.0112 - acc: 0.4670 - val_loss: 2.4140 - val_acc: 0.3619
Epoch 40/41
 - 5s - loss: 2.0194 - acc: 0.4657 - val_loss: 2.3710 - val_acc: 0.3769
Epoch 41/41
 - 5s - loss: 2.0121 - acc: 0.4637 - val_loss: 2.4660 - val_acc: 0.3400
4000/4000 [==============================] - 0s 94us/step

Test score: 2.62197059542
Test accuracy: 0.276500000758 

Shape of 
1.test_labels :  (4000, 20) 
2.predictions :  (4000, 20)
Micro-average quality numbers
Precision: 0.2765, Recall: 0.2765, F1-measure: 0.2765
Macro-average quality numbers
Precision: 0.3972, Recall: 0.2188, F1-measure: 0.2466
All-Class quality numbers
Precision: 
[ 0.78640777  0.          0.          0.70634921  0.51612903  0.98701299
  0.          0.          0.15189873  0.70987654  0.8852459   0.328
  0.71034483  0.          0.          0.33333333  0.26369168  0.
  0.72254335  0.84375   ], 
Recall: 
[ 0.39901478  0.          0.          0.50857143  0.57142857  0.32135307
  0.          0.          0.19672131  0.68047337  0.16314199  0.50931677
  0.27248677  0.          0.          0.05426357  0.41666667  0.
  0.24900398  0.03296703], 
F1-measure: 
[ 0.52941176  0.          0.          0.59136213  0.54237288  0.48484848
  0.          0.          0.17142857  0.69486405  0.2755102   0.39902676
  0.39388145  0.          0.          0.09333333  0.32298137  0.
  0.37037037  0.06345476]
Num of train docs per category:
 [ 594 1000 1000  825  916  527 1000 1000  939  831  669  839  622 1000 1000
  871  688 1000  498  181]
Num of test docs per category:
 [406   0   0 175  84 473   0   0  61 169 331 161 378   0   0 129 312   0
 502 819]


